You are a senior chip design engineer who is an expert with Verilog HDL, especially designing AI accelerators for SoCs. I want you to help me join efabless'es 4 AI contest. The challenge aims to leverage generative AI to develop an open-source hardware accelerator designed explicitly for Keyword Spotting (KWS) applications on the Caravel System-on-Chip.Participants will utilize generative AI to optimize the KWS machine learning model and/or the audio features extractor (e.g., MFCC) to create an energy-efficient KWS accelerator that seamlessly integrates into the Caravel SoC environment. The discription is "In this contest, we invite you to utilize generative AI such as chatGPT, Gemini, Claude, Copilot, or similar tools to design a chipIgnite project targeted to an open-source hardware accelerator designed specifically for Keyword Spotting (KWS) applications.
Your design must be implemented using Efabless’ chipIgnite that includes the Caravel SoC for rapid chip-level integration and the open-source design tools.
The objectives of this challenge go beyond creating designs; It’s about raising awareness within the open source silicon design community about the wide range of possibilities for using Generative AI in chip design.
A successful project must provide all information necessary for other members of the community to reproduce your work. This includes detailed design documentation, the prompts used to generate the design, any required scripts or automation, and verification testbenches to demonstrate your design meets its intended functionality." 
Based on the requirements for hardware acceleration, model accuracy, complexity, and compatibility, I recommend using a Convolutional Neural Network (CNN) based model for the Keyword Spotting (KWS) accelerator. CNNs have shown excellent performance in speech recognition tasks, including KWS, and their architecture is well-suited for hardware implementation. 
One specific CNN model that has been widely used for KWS is the CNN-KWS model, also known as the "Hello Edge" model. This model was introduced in the paper "Hello Edge: Keyword Spotting on Microcontrollers" by Zhang et al. (2017). The CNN-KWS model has several advantages:
1. Compact architecture: The model consists of a few convolutional layers followed by fully connected layers, making it relatively lightweight and suitable for resource-constrained hardware.
2. High accuracy: Despite its compact size, the CNN-KWS model achieves high accuracy in keyword spotting tasks, with reported accuracies of over 90% on popular KWS datasets like the Google Speech Commands dataset.
3. Compatibility with hardware: The convolutional and fully connected layers in the CNN-KWS model can be efficiently mapped to hardware resources like multiply-accumulate (MAC) units and memory buffers, enabling parallel and pipelined execution.
4. Energy efficiency: The compact size and hardware-friendly architecture of the CNN-KWS model make it energy-efficient, which is crucial for battery-powered devices and edge computing scenarios.
Here's a high-level overview of the CNN-KWS model architecture:
1. Input: Mel-frequency cepstral coefficients (MFCC) features extracted from the audio signal.
This layer has been already implemented with top module code "I have already created the mfcc module and the code is "`include "preemphasis_filter.v"
`include "framing_windowing.v"
`include "goertzel_dft.v"
`include "mel_filterbank.v"
`include "logarithm_comp.v"
`include "dct_comp.v"
module mfcc_accelerator (
input wire clk,
input wire rst_n,
input wire [15:0] audio_in,
input wire audio_valid,
output wire [31:0] mfcc_out,
output wire mfcc_valid,
input wire [7:0] frame_size,
input wire [7:0] frame_overlap,
input wire [7:0] num_mel_filters,
input wire [7:0] num_mfcc_coeffs,
input wire [7:0] num_freqs,
input wire [15:0] target_freqs [0:255],
input wire [15:0] goertzel_coefs [0:255]
);
// Signal declarations
wire [15:0] preemph_out;
wire preemph_valid;
wire [15:0] framed_out;
wire framed_valid;
wire [31:0] dft_out;
wire dft_valid;
wire [31:0] mel_fbank_out;
wire mel_fbank_valid;
wire [31:0] log_out;
wire log_valid;
wire [31:0] dct_out;
wire dct_valid;
// Pre-emphasis filtering
preemphasis_filter preemph (
.clk(clk),
.rst_n(rst_n),
.audio_in(audio_in),
.audio_valid(audio_valid),
.preemph_out(preemph_out),
.preemph_valid(preemph_valid)
);
// Framing and windowing
framing_windowing framing (
.clk(clk),
.rst_n(rst_n),
.preemph_out(preemph_out),
.preemph_valid(preemph_valid),
.frame_size(frame_size),
.frame_overlap(frame_overlap),
.framed_out(framed_out),
.framed_valid(framed_valid)
);
// Discrete Fourier Transform (DFT) using Goertzel's algorithm
goertzel_dft dft (
.clk(clk),
.rst_n(rst_n),
.framed_out(framed_out),
.framed_valid(framed_valid),
.num_freqs(num_freqs),
.target_freqs(target_freqs),
.goertzel_coefs(goertzel_coefs),
.dft_out(dft_out),
.dft_valid(dft_valid)
);
// Mel-scale filterbank application
mel_filterbank mel_fbank (
.clk(clk),
.rst_n(rst_n),
.dft_out(dft_out),
.dft_valid(dft_valid),
.mel_fbank_out(mel_fbank_out),
.mel_fbank_valid(mel_fbank_valid)
);
// Logarithm computation
logarithm_comp log_comp (
.clk(clk),
.rst_n(rst_n),
.mel_fbank_out(mel_fbank_out),
.mel_fbank_valid(mel_fbank_valid),
.log_out(log_out),
.log_valid(log_valid)
);
// Discrete Cosine Transform (DCT)
dct_comp dct (
.clk(clk),
.rst_n(rst_n),
.log_out(log_out),
.log_valid(log_valid),
.num_mfcc_coeffs(num_mfcc_coeffs),
.dct_out(dct_out),
.dct_valid(dct_valid)
);
// Output assignment
assign mfcc_out = dct_out;
assign mfcc_valid = dct_valid;
endmodule""
2. Convolutional layers: Two or three convolutional layers with small kernel sizes (e.g., 3x3) and a small number of filters (e.g., 32 or 64) to learn local patterns in the MFCC features.
3. Pooling layers: Max pooling layers to reduce the spatial dimensions and provide translation invariance.
4. Fully connected layers: One or two fully connected layers to learn high-level representations and perform classification.
5. Output layer: A softmax layer to produce the probability distribution over the keyword classes.
To optimize the CNN-KWS model for hardware implementation, you can consider the following techniques:
1. Quantization: Reduce the bitwidth of weights and activations to minimize storage and computation requirements. For example, using 8-bit fixed-point representation instead of 32-bit floating-point.
2. Pruning: Remove less significant weights or connections in the model to reduce complexity and memory footprint without significant accuracy loss.
3. Architectural optimizations: Explore variations of the CNN-KWS architecture, such as using depthwise separable convolutions or residual connections, to improve efficiency and accuracy.
Assist in optimizing the CNN-KWS model architecture, suggesting quantization and pruning strategies, and generating optimized HDL code for hardware implementation.
According to the "Hello Edge: Keyword Spotting on Microcontrollers" by Zhang et al. (2017) can you create a prompt for the top "cnn_kws_accel" module using synthesizable verilog?